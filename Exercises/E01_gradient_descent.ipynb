{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a href=\"https://colab.research.google.com/github/kokchun/Maskininlarning-AI21/blob/main/Exercises/E01_gradient_descent.ipynb\" target=\"_parent\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> &nbsp; to see hints and answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Gradient descent exercises\n",
    "\n",
    "---\n",
    "These are introductory exercises in Machine learning with focus in **gradient descent** .\n",
    "\n",
    "<p class = \"alert alert-info\" role=\"alert\"><b>Note</b> all datasets used in this exercise can be found under Data folder of the course Github repo</p>\n",
    "\n",
    "<p class = \"alert alert-info\" role=\"alert\"><b>Note</b> that in cases when you start to repeat code, try not to. Create functions to reuse code instead. </p>\n",
    "\n",
    "<p class = \"alert alert-info\" role=\"alert\"><b>Remember</b> to use <b>descriptive variable, function, index </b> and <b> column names</b> in order to get readable code </p>\n",
    "\n",
    "The number of stars (\\*), (\\*\\*), (\\*\\*\\*) denotes the difficulty level of the task\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Simulate dataset (*)\n",
    "\n",
    "Simulate datasets according to these rules:\n",
    "\n",
    "- set random seed to 42\n",
    "- (1000,2) samples from $X \\sim \\mathcal{U}(0,1)$ , i.e. 1000 rows, 2 columns. \n",
    "- 1000 samples from $\\epsilon \\sim \\mathcal{N}(0,1)$\n",
    "- $y = 3x_1 + 5x_2 + 3 + \\epsilon$ , where $x_i$ is column $i$ of $X$\n",
    "\n",
    "Finally add a column of ones for the intercept to $X$.\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary>Hint</summary>\n",
    "\n",
    "Use for simulating X\n",
    "\n",
    "´´´\n",
    "np.random.rand(samples, 2)\n",
    "´´´\n",
    "\n",
    "to concatenate with ones, use ```np.c_[..., ...]```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary>Answer</summary>\n",
    "\n",
    "```\n",
    "array([[1.        , 0.37454012, 0.95071431],\n",
    "       [1.        , 0.73199394, 0.59865848],\n",
    "       [1.        , 0.15601864, 0.15599452],\n",
    "       [1.        , 0.05808361, 0.86617615],\n",
    "       [1.        , 0.60111501, 0.70807258]])\n",
    "\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.37454012, 0.95071431],\n",
       "       [1.        , 0.73199394, 0.59865848],\n",
       "       [1.        , 0.15601864, 0.15599452],\n",
       "       ...,\n",
       "       [1.        , 0.75137509, 0.65695516],\n",
       "       [1.        , 0.95661462, 0.06895802],\n",
       "       [1.        , 0.05705472, 0.28218707]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "X = np.random.rand(1000, 2) \n",
    "# np.random.randint() discrete uniform distribution\n",
    "# np.random.rand() uniform distribution of U[0,1)\n",
    "e = np.random.randn(1000)\n",
    "#X1 = X[:][:,0]\n",
    "#X2 = X[:][:,1]\n",
    "X1 = X[:,0]\n",
    "X2 = X[:,1]\n",
    "y = 3*X1+ 5*X2 + 3 + e\n",
    "\n",
    "ones = np.ones(1000)\n",
    "np.c_[ones, X1, X2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Gradient descent - learning rate (*)\n",
    "\n",
    "Use gradient descent to calculate $\\vec{\\theta} = (\\theta_0, \\theta_1, \\theta_2)^T$ \n",
    "\n",
    "&nbsp; a) Use $\\eta = 0.1$ and simulate 500 epochs of batch gradient descent. Plot the resulting $\\vec{\\theta}$ values for every 5th epoch. (*)\n",
    "\n",
    "&nbsp; b) Do the same as for a) but with learning rate $\\eta = 0.01$, 5000 epochs and plot every 20 step. What do you notice when changing the learning rate? (*)\n",
    "\n",
    "&nbsp; c) Experiment with larger and smaller $\\eta$ and see what happens.\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary>Hint</summary>\n",
    "\n",
    "Use for simulating X\n",
    "\n",
    "´´´\n",
    "np.random.rand(samples, 2)\n",
    "´´´\n",
    "\n",
    "to concatenate with ones, use ```np.c_[..., ...]```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary>Answer</summary>\n",
    "\n",
    "a) \n",
    "\n",
    "<img src=\"../assets/grad_desc_converg.png\" height=\"200\"/>\n",
    "\n",
    "b) \n",
    "\n",
    "<img src=\"../assets/grad_desc_converg_001.png\" height=\"200\"/>\n",
    "\n",
    "</details>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Stochastic Gradient Descent - learning rate (**)\n",
    "\n",
    "Repeat task 1 but using stochastic gradient descent instead. Also adjust number of epochs to see if you can find convergence. What kind of conclusions can you draw from your experiments. (**)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Mini Batch Gradient Descent (**)\n",
    "\n",
    "Now try different sizes of mini-batches and make some exploratory plots to see convergence. Also you can make comparison to the other algorithms by using same $\\eta$ and same amount of epochs to see how they differ from each other in terms of convergence. (**)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4b4b6acbae5a80fa52687d6cfe26b17b58271eb94125fc5bdb7b9b1f3cd1f65d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 ('Maskininlarning-Yuna-Liu-sgUjmrCu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
